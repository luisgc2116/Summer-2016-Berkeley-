print(__doc__)
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.datasets.samples_generator import make_blobs
from sklearn.preprocessing import StandardScaler
import rtpipe
from scipy.stats import gaussian_kde
from scipy import linalg as la
from sklearn.neighbors import NearestNeighbors
from sklearn.neighbors import kneighbors_graph

fig0 = "cands_14A-425_sb29612394_1.56903.3271372338_sc24seg0.pkl"
fig01 = "cands_15B-305_sb31388707_1.57340.27658104167_merge.pkl"
fig11 = "cands_16A-459_sb32072968_1_000.57530.6971321412_merge.pkl"

candsfile = "cands_12A-336_sb9667618_1b.56040.87127945602_sc8.pkl"


def epsValue( input_file ):
   """

    Function: Takes a candidate file(input_file) and outputs the correct eps value for DBSCAN.

    input: input_file 
    output: ?

   """
   candsfile = fig11
    loc, prop, d = rtpipe.parsecands.read_candidates(candsfile, returnstate=True)

    times = rtpipe.parsecands.int2mjd(d, loc)
    dms = np.array(d['dmarr'])[loc[:,3]]
    snrs = prop[:,0]

    X0 = np.vstack((times,dms)).transpose()
    X = StandardScaler().fit_transform(X0)


    #Finding the distance between points -> putting them into an array
    nbrs = NearestNeighbors(n_neighbors=2).fit(X)
    distances, indices = nbrs.kneighbors(X)
    #print np.mean(distances)


    #Take the last column of the distance array and sort them in ascending order
    d = sorted(distances[:,-1])

    return out


#Plot histogram with x -> number of points, y -> sorted distances
plt.plot(d)
#plt.hist(sorted(distances[:,-1]))


#------------------------Compute DBSCAN-----------------------------------
def compDBSCAN ( eps, input_file ):

    """
    Function: Takes the previously calculated eps value and candidate file to output 

    input: eps value, input_file
    output: number of clusters, arrays of each cluster, noise
    """
    
    db = DBSCAN(eps=.045, min_samples=2, metric='cityblock').fit(X)


    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
    core_samples_mask[db.core_sample_indices_] = True
    labels = db.labels_

    # Number of clusters in labels, ignoring noise if present.
    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)

    # Labeling noise
    unique_labels = set(labels)
    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))
    for k, col in zip(unique_labels, colors):
        if k == -1:
        # Black used for noise.
            col = 'k'

    class_member_mask = (labels == k)

    xy = X[class_member_mask & core_samples_mask]
    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,
             markeredgecolor='k', markersize=3, alpha=.4)

    xy = X[class_member_mask & ~core_samples_mask]
    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,
             markeredgecolor='k', markersize=1, alpha=.8)


    #Creates arrays of individual clusters
    clusters = [X0[labels == i] for i in xrange(n_clusters_)]

    return 






plt.xlabel('Time(s)')
plt.ylabel('DM(pc/cc)')
plt.title('Estimated Number of Clusters: %d' % n_clusters_)
plt.show()


plt.xlabel('')
plt.ylabel('')
plt.title('Eps Plot')

plt.show()
